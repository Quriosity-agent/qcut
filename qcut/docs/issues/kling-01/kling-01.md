# Kling-01

Integration of Kling Video APIs from fal.ai into QCut.

## Overview

This document covers the integration of Kling Video endpoints from fal.ai, as implemented in QCut's AI Video Generation dialog.

### UI Structure

The AI Video Generation dialog (`ai.tsx`) contains four tabs:
- **Text** - Text-to-video generation
- **Image** - Image-to-video generation (includes V2V models)
- **Avatar** - Audio-driven avatar video generation
- **Upscale** - Video upscaling and enhancement

### Implemented Kling Models

From `ai-constants.ts`, the following Kling models are configured:

**Text Tab:**
- `kling_v2_5_turbo` - Kling v2.5 Turbo Pro (text-to-video and image-to-video)
- `kling_v2` - Kling v2.1 Master

**Image Tab:**
- `kling_v2_5_turbo_i2v` - Kling v2.5 Turbo Pro I2V
- `kling_o1_v2v_reference` - Kling O1 Video Reference (V2V)
- `kling_o1_v2v_edit` - Kling O1 Video Edit (V2V)
- `kling_o1_i2v` - Kling O1 Image-to-Video

**Avatar Tab:**
- `kling_avatar_pro` - Kling Avatar Pro
- `kling_avatar_standard` - Kling Avatar Standard
- `kling_o1_ref2video` - Kling O1 Reference-to-Video (uses reference images)

---

## Kling O1 Models

### Video-to-Video Reference
```typescript
// From ai-constants.ts
{
  id: "kling_o1_v2v_reference",
  name: "Kling O1 Video Reference",
  description: "Generate new shots guided by input reference video, preserving motion and camera style",
  price: "0.112",
  resolution: "1080p",
  max_duration: 10,
  category: "image",
  requiredInputs: ["sourceVideo"],
  endpoints: {
    image_to_video: "fal-ai/kling-video/o1/video-to-video/reference",
  },
  default_params: {
    duration: 5,
    aspect_ratio: "auto",
  },
  supportedDurations: [5, 10],
  supportedAspectRatios: ["auto", "16:9", "9:16", "1:1"],
}
```

### Video-to-Video Edit
```typescript
{
  id: "kling_o1_v2v_edit",
  name: "Kling O1 Video Edit",
  description: "Edit videos through natural language instructions while preserving motion structure",
  price: "0.168",
  resolution: "1080p",
  max_duration: 10,
  category: "image",
  requiredInputs: ["sourceVideo"],
  endpoints: {
    image_to_video: "fal-ai/kling-video/o1/video-to-video/edit",
  },
  default_params: {
    duration: 5,
  },
  supportedDurations: [5, 10],
}
```

### Reference-to-Video
```typescript
{
  id: "kling_o1_ref2video",
  name: "Kling O1 Reference-to-Video",
  description: "Transform reference images and elements into consistent video scenes",
  price: "0.112",
  resolution: "1080p",
  max_duration: 10,
  category: "avatar", // Avatar tab - uses reference images
  requiredInputs: ["referenceImages"],
  endpoints: {
    image_to_video: "fal-ai/kling-video/o1/reference-to-video",
  },
  default_params: {
    duration: 5,
    aspect_ratio: "16:9",
    cfg_scale: 0.5,
    negative_prompt: "blur, distort, low quality",
  },
  supportedDurations: [5, 10],
  supportedAspectRatios: ["16:9", "9:16", "1:1"],
}
```

### Image-to-Video (First/Last Frame)
```typescript
{
  id: "kling_o1_i2v",
  name: "Kling O1 Image-to-Video",
  description: "Animate transitions between start and end frames with cinematic motion",
  price: "0.112",
  resolution: "1080p",
  max_duration: 10,
  category: "image",
  requiredInputs: ["firstFrame"],
  endpoints: {
    image_to_video: "fal-ai/kling-video/o1/image-to-video",
  },
  default_params: {
    duration: 5,
  },
  supportedDurations: [5, 10],
}
```

---

## Kling O1 API Client Functions

### generateKlingO1Video
For video-to-video transformations (Reference and Edit models).

```typescript
export interface KlingO1V2VRequest {
  model: string;
  prompt: string;
  sourceVideo: File;
  duration?: 5 | 10;
  aspect_ratio?: "auto" | "16:9" | "9:16" | "1:1";
  keep_audio?: boolean;
}

export async function generateKlingO1Video(
  request: KlingO1V2VRequest
): Promise<VideoGenerationResponse>
```

**Flow:**
1. Validates FAL API key is configured
2. Validates prompt (max 2500 chars)
3. Converts source video to base64 data URL
4. Builds payload with `video_url`, `prompt`, `duration`, `aspect_ratio`
5. Sends request to FAL API with 3-minute timeout
6. Returns `VideoGenerationResponse` with job_id and video URL

### generateKlingO1RefVideo
For reference-to-video generation.

```typescript
export interface KlingO1Ref2VideoRequest {
  model: string;
  prompt: string;
  image_url: string;
  duration?: 5 | 10;
  aspect_ratio?: "16:9" | "9:16" | "1:1";
  cfg_scale?: number;
  negative_prompt?: string;
}

export async function generateKlingO1RefVideo(
  request: KlingO1Ref2VideoRequest
): Promise<VideoGenerationResponse>
```

**Payload:**
```typescript
{
  prompt: trimmedPrompt,
  image_urls: [request.image_url], // API expects array
  duration,
  aspect_ratio,
  cfg_scale,
  negative_prompt,
}
```

---

## UI Components

### Video-to-Video Mode in Image Tab

The `AIImageUploadSection` component (`ai-image-upload.tsx`) now supports three modes:

1. **I2V Mode** - Single image upload for image-to-video models
2. **F2V Mode** - Dual frame upload for frame-to-video models
3. **V2V Mode** - Source video upload for video-to-video models

Mode detection uses `MODEL_HELPERS`:
```typescript
// Check if V2V mode
const requiresSourceVideo = selectedModels.some((id) =>
  MODEL_HELPERS.requiresSourceVideo(id)
);

// Check if F2V mode
const requiresFrameToFrame = selectedModels.some((id) =>
  MODEL_HELPERS.requiresFrameToFrame(id)
);
```

### V2V Upload UI
```typescript
<FileUpload
  id="ai-source-video-input"
  label="Upload Source Video"
  helperText="Required for video-to-video transformation"
  fileType="video"
  acceptedTypes={UPLOAD_CONSTANTS.ALLOWED_VIDEO_TYPES}
  maxSizeBytes={UPLOAD_CONSTANTS.MAX_VIDEO_SIZE_BYTES}
  // ...
/>
```

---

## Text-to-Video Models

### Kling v2.5 Turbo Pro

```typescript
// From ai-constants.ts
{
  id: "kling_v2_5_turbo",
  name: "Kling v2.5 Turbo Pro",
  description: "Latest Kling model with enhanced turbo performance",
  price: "0.18",
  resolution: "1080p",
  max_duration: 10,
  category: "text",
  endpoints: {
    text_to_video: "fal-ai/kling-video/v2.5-turbo/pro/text-to-video",
    image_to_video: "fal-ai/kling-video/v2.5-turbo/pro/image-to-video",
  },
  default_params: {
    duration: 5,
    resolution: "1080p",
    cfg_scale: 0.5,
    aspect_ratio: "16:9",
    enhance_prompt: true,
  },
}
```

### Kling v2.1 Master

```typescript
{
  id: "kling_v2",
  name: "Kling v2.1",
  description: "Premium model with unparalleled motion fluidity",
  price: "0.15",
  resolution: "1080p",
  max_duration: 10,
  endpoints: {
    text_to_video: "fal-ai/kling-video/v2.1/master",
  },
  default_params: {
    duration: 5,
    resolution: "1080p",
  },
}
```

---

## Avatar Models

### Kling Avatar Pro

```typescript
{
  id: "kling_avatar_pro",
  name: "Kling Avatar Pro",
  description: "Premium avatar video generation from image + audio",
  price: "0.25",
  resolution: "1080p",
  max_duration: 10,
  category: "avatar",
  requiredInputs: ["characterImage", "audioFile"],
  endpoints: {
    text_to_video: "fal-ai/kling-video/v1/pro/ai-avatar",
  },
}
```

### Kling Avatar Standard

```typescript
{
  id: "kling_avatar_standard",
  name: "Kling Avatar Standard",
  description: "Standard avatar video generation from image + audio",
  price: "0.15",
  resolution: "720p",
  max_duration: 10,
  category: "avatar",
  requiredInputs: ["characterImage", "audioFile"],
  endpoints: {
    text_to_video: "fal-ai/kling-video/v1/standard/ai-avatar",
  },
}
```

---

## Upload Constants

```typescript
export const UPLOAD_CONSTANTS = {
  // Image uploads
  MAX_IMAGE_SIZE_BYTES: 10 * 1024 * 1024, // 10MB
  MAX_IMAGE_SIZE_LABEL: "10MB",

  // Audio uploads
  ALLOWED_AUDIO_TYPES: ["audio/mpeg", "audio/wav", "audio/aac"],
  MAX_AUDIO_SIZE_BYTES: 50 * 1024 * 1024, // 50MB
  AUDIO_FORMATS_LABEL: "MP3, WAV, AAC",

  // Video uploads
  ALLOWED_VIDEO_TYPES: ["video/mp4", "video/quicktime", "video/x-msvideo"],
  MAX_VIDEO_SIZE_BYTES: 100 * 1024 * 1024, // 100MB
  VIDEO_FORMATS_LABEL: "MP4, MOV, AVI",
} as const;
```

---

## Bug Fix: kling_o1_ref2video Generation Failed (2025-12-03) âœ… RESOLVED

### é—®é¢˜æè¿° (Issue Description)
ç”¨æˆ·åœ¨ Avatar æ ‡ç­¾é¡µé€‰æ‹© `kling_o1_ref2video` æ¨¡å‹åç‚¹å‡»ç”Ÿæˆï¼Œè¿”å› `undefined` å“åº”ï¼Œç”Ÿæˆå¤±è´¥ã€‚

### é”™è¯¯æ—¥å¿—åˆ†æ (Error Log Analysis)
```
step 5: sending generation request for kling_o1_ref2video (avatar tab)
step 5a: post-API response analysis
   - response received: false
   - response is undefined/null
âš ï¸ Response has neither job_id nor video_url: undefined
```

å…³é”®çº¿ç´¢ï¼š
```
hasSelectedImage: false
imageFile: null
```

### æ ¹æœ¬åŸå›  (Root Cause) - ä¸¤ä¸ªé—®é¢˜

**é—®é¢˜ 1: `generateAvatarVideo` å‡½æ•°ç¼ºå°‘å¤„ç†é€»è¾‘**
1. æ¨¡å‹ `kling_o1_ref2video` åœ¨ `ai-constants.ts` ä¸­é…ç½®ä¸º `category: "avatar"`
2. ç”¨æˆ·ä» Avatar æ ‡ç­¾é¡µé€‰æ‹©è¯¥æ¨¡å‹æ—¶ï¼Œè°ƒç”¨ `generateAvatarVideo` å‡½æ•°
3. ä½†è¯¥å‡½æ•°åªå¤„ç†ä»¥ä¸‹æ¨¡å‹ï¼š
   - `wan_animate_replace`
   - `kling_avatar_pro` / `kling_avatar_standard`
   - `bytedance_omnihuman_v1_5`
4. `kling_o1_ref2video` æ²¡æœ‰å¯¹åº”å¤„ç†é€»è¾‘ï¼Œè¿›å…¥ `else` åˆ†æ”¯æŠ›å‡º `Error: Unsupported avatar model`

**é—®é¢˜ 2: éªŒè¯é€»è¾‘è·³è¿‡äº†å›¾ç‰‡æ£€æŸ¥** âš ï¸
```typescript
// åŸä»£ç  (é”™è¯¯)
if (modelId === "kling_o1_ref2video") {
  // Reference images are optional enhancement, no validation needed
  continue;  // è¿™é‡Œè·³è¿‡äº†éªŒè¯ï¼
}
```
éªŒè¯ä»£ç é”™è¯¯åœ°è®¤ä¸º "reference images are optional"ï¼Œå¯¼è‡´æ²¡æœ‰æ£€æŸ¥ `avatarImage`ã€‚

ç”±äº `avatarImage` ä¸º `null`ï¼ŒAPI è°ƒç”¨æ¡ä»¶ `activeTab === "avatar" && avatarImage` ä¸º `false`ï¼Œå¯¼è‡´ `generateAvatarVideo` ä»æœªè¢«è°ƒç”¨ï¼Œ`response` ä¿æŒ `undefined`ã€‚

### ä¿®å¤æ–¹æ¡ˆ (Fixes Applied) âœ…

**ä¿®å¤ 1: æ·»åŠ  API å¤„ç†é€»è¾‘** (`ai-video-client.ts`)
```typescript
} else if (request.model === "kling_o1_ref2video") {
  // Kling O1 Reference-to-Video: transforms reference images into video scenes
  // Uses the image_to_video endpoint with image_urls array and prompt
  endpoint = modelConfig.endpoints.image_to_video || "";

  // Upload character image to get URL (FAL expects URLs for this endpoint)
  console.log("ğŸ“¤ Uploading reference image to FAL...");
  const imageUrl = await falAIClient.uploadImageToFal(request.characterImage);
  console.log("âœ… Reference image uploaded:", imageUrl);

  // Build prompt with @Image1 reference syntax
  let enhancedPrompt = request.prompt || "";
  if (!enhancedPrompt.includes("@Image")) {
    enhancedPrompt = `Use @Image1 as the reference. ${enhancedPrompt}`.trim();
  }

  payload = {
    prompt: enhancedPrompt,
    image_urls: [imageUrl],
    duration: String(request.duration || modelConfig.default_params?.duration || 5),
    aspect_ratio: modelConfig.default_params?.aspect_ratio || "16:9",
    ...(modelConfig.default_params?.cfg_scale && { cfg_scale: modelConfig.default_params.cfg_scale }),
    ...(modelConfig.default_params?.negative_prompt && { negative_prompt: modelConfig.default_params.negative_prompt }),
  };
}
```

**ä¿®å¤ 2: æ·»åŠ éªŒè¯é€»è¾‘** (`use-ai-generation.ts`)
```typescript
// ä¿®å¤åçš„ä»£ç 
// Reference-to-video model requires avatar/reference image
if (modelId === "kling_o1_ref2video" && !avatarImage) {
  validationError =
    "Kling O1 Reference-to-Video requires a reference image";
  break;
}
```

### æ–‡ä»¶ä¿®æ”¹ (Files Modified)
- `qcut/apps/web/src/lib/ai-video-client.ts`
  - æ·»åŠ  `import { falAIClient } from "./fal-ai-client";` (line 7)
  - æ·»åŠ  `kling_o1_ref2video` å¤„ç†åˆ†æ”¯ (lines 2881-2909)
- `qcut/apps/web/src/components/editor/media-panel/views/use-ai-generation.ts`
  - ä¿®å¤éªŒè¯é€»è¾‘ï¼Œè¦æ±‚ `avatarImage` (lines 819-824)

### æŠ€æœ¯ç»†èŠ‚ (Technical Details)
- FAL API `reference-to-video` ç«¯ç‚¹æœŸæœ› `image_urls` ä¸º URL æ•°ç»„ï¼Œä¸æ˜¯ base64
- ä½¿ç”¨ `falAIClient.uploadImageToFal()` ä¸Šä¼ å›¾ç‰‡è·å– URL
- éœ€è¦ä½¿ç”¨ `@Image1` è¯­æ³•åœ¨ prompt ä¸­å¼•ç”¨ä¸Šä¼ çš„å›¾ç‰‡
- è‡ªåŠ¨æ·»åŠ  `cfg_scale` å’Œ `negative_prompt` ä» default_params
- ç”¨æˆ·å¿…é¡»å…ˆä¸Šä¼ å‚è€ƒå›¾ç‰‡æ‰èƒ½ä½¿ç”¨æ­¤æ¨¡å‹

### éªŒè¯æ¸…å• (Verification Checklist)
- [x] Import `falAIClient` added to ai-video-client.ts
- [x] Handler for `kling_o1_ref2video` added in `generateAvatarVideo`
- [x] Model category correctly set to `"avatar"` in ai-constants.ts
- [x] Documentation updated to reflect correct model placement
- [x] **Validation logic fixed** to require `avatarImage` for `kling_o1_ref2video`

### ä¿®å¤éªŒè¯ (Fix Verified) - ç¬¬ä¸€é˜¶æ®µ

éªŒè¯æ—¥å¿—æ˜¾ç¤ºéªŒè¯é€»è¾‘ç”Ÿæ•ˆï¼š
```
âŒ Validation failed!
  - Reason: Kling O1 Reference-to-Video requires a reference image
```

ä½†å‘ç°æ–°é—®é¢˜ï¼šç”¨æˆ·ä¸Šä¼ åˆ° "Reference Images" (Ref 1, Ref 2...) åŒºåŸŸï¼Œä½†ä»£ç æ£€æŸ¥çš„æ˜¯ `avatarImage`ï¼ˆä¸åŒçš„çŠ¶æ€å˜é‡ï¼‰ã€‚

---

## Bug Fix: ç¬¬äºŒé˜¶æ®µ - referenceImages çŠ¶æ€æœªä¼ é€’ (2025-12-03) âœ… RESOLVED

### é—®é¢˜å‘ç°
ç”¨æˆ·æˆªå›¾æ˜¾ç¤ºå·²ä¸Šä¼  Reference Images (Ref 1, Ref 2)ï¼Œä½†éªŒè¯ä»ç„¶å¤±è´¥ã€‚

åŸå› åˆ†æï¼š
- UI æœ‰ä¸¤ä¸ªç‹¬ç«‹çš„å›¾ç‰‡ä¸Šä¼ åŒºåŸŸï¼š
  1. `avatarImage` - å•ä¸ªè§’è‰²å›¾ç‰‡
  2. `referenceImages` - 6ä¸ªå‚è€ƒå›¾ç‰‡æ§½ä½ (Ref 1-6)
- `kling_o1_ref2video` é…ç½®ä¸º `requiredInputs: ["referenceImages"]`
- ä½† `referenceImages` çŠ¶æ€**æ²¡æœ‰ä¼ é€’**åˆ° `useAIGeneration` hook

### ä¿®å¤å†…å®¹

**ä¿®å¤ 1: æ·»åŠ  referenceImages åˆ° props æ¥å£** (`ai-types.ts`)
```typescript
// Avatar-specific props
avatarImage?: File | null;
audioFile?: File | null;
sourceVideo?: File | null;
referenceImages?: (File | null)[];  // æ–°å¢
```

**ä¿®å¤ 2: ä¼ é€’ referenceImages åˆ° hook** (`ai.tsx`)
```typescript
const generation = useAIGeneration({
  // ...
  referenceImages,  // æ–°å¢
  // ...
});
```

**ä¿®å¤ 3: æ¥æ”¶ referenceImages** (`use-ai-generation.ts`)
```typescript
// Avatar-specific props
avatarImage,
audioFile,
sourceVideo,
referenceImages,  // æ–°å¢
```

**ä¿®å¤ 4: æ›´æ–°éªŒè¯é€»è¾‘** (`use-ai-generation.ts`)
```typescript
// Reference-to-video model requires at least one reference image
if (modelId === "kling_o1_ref2video") {
  const hasReferenceImage = referenceImages?.some((img) => img !== null);
  if (!hasReferenceImage) {
    validationError =
      "Kling O1 Reference-to-Video requires at least one reference image";
    break;
  }
}
```

**ä¿®å¤ 5: æ›´æ–° API è°ƒç”¨é€»è¾‘** (`use-ai-generation.ts`)
```typescript
} else if (activeTab === "avatar") {
  // Special handling for kling_o1_ref2video which uses referenceImages
  if (modelId === "kling_o1_ref2video") {
    const firstRefImage = referenceImages?.find((img) => img !== null);
    if (firstRefImage) {
      response = await generateAvatarVideo({
        model: modelId,
        characterImage: firstRefImage,
        prompt: prompt.trim() || undefined,
      });
    }
  } else if (avatarImage) {
    // Other avatar models use avatarImage
    response = await generateAvatarVideo({...});
  }
}
```

### æ–‡ä»¶ä¿®æ”¹ (Files Modified)
- `qcut/apps/web/src/components/editor/media-panel/views/ai-types.ts`
  - æ·»åŠ  `referenceImages` åˆ° `UseAIGenerationProps` æ¥å£
- `qcut/apps/web/src/components/editor/media-panel/views/ai.tsx`
  - ä¼ é€’ `referenceImages` åˆ° `useAIGeneration` hook
- `qcut/apps/web/src/components/editor/media-panel/views/use-ai-generation.ts`
  - æ¥æ”¶ `referenceImages` prop
  - æ›´æ–°éªŒè¯é€»è¾‘æ£€æŸ¥ `referenceImages`
  - æ›´æ–° API è°ƒç”¨ä½¿ç”¨ `referenceImages[0]` ä½œä¸º characterImage
  - æ·»åŠ  `referenceImages` åˆ°ä¾èµ–æ•°ç»„

### ç”¨æˆ·æ“ä½œæŒ‡å— (User Guide)
ä½¿ç”¨ Kling O1 Reference-to-Video æ¨¡å‹çš„æ­¥éª¤ï¼š
1. è¿›å…¥ Avatar æ ‡ç­¾é¡µ
2. **ä¸Šä¼ è‡³å°‘ä¸€å¼ å‚è€ƒå›¾ç‰‡åˆ° "Reference Images" åŒºåŸŸ** (Ref 1, Ref 2, ... Ref 6)
3. è¾“å…¥ promptï¼ˆå¯é€‰ï¼Œå»ºè®®ä½¿ç”¨ `@Image1`, `@Image2` è¯­æ³•å¼•ç”¨å›¾ç‰‡ï¼‰
4. é€‰æ‹© `kling_o1_ref2video` æ¨¡å‹
5. ç‚¹å‡»ç”Ÿæˆ

---

## Bug Fix: ç¬¬ä¸‰é˜¶æ®µ - CORS é”™è¯¯ (2025-12-03) âœ… RESOLVED

### é—®é¢˜æè¿° (Issue Description)
ç”¨æˆ·ä¸Šä¼  Reference Images åç‚¹å‡»ç”Ÿæˆï¼Œå‡ºç° CORS é”™è¯¯ï¼š
```
Access to fetch at 'https://fal.run/upload' from origin 'app://.' has been blocked by CORS policy
```

### é”™è¯¯æ—¥å¿—åˆ†æ (Error Log Analysis)
```
ğŸ“¤ Uploading reference image to FAL...
Access to fetch at 'https://fal.run/upload' from origin 'app://.' has been blocked by CORS policy:
Response to preflight request doesn't pass access control check:
No 'Access-Control-Allow-Origin' header is present on the requested resource.
```

å…³é”®ä¿¡æ¯ï¼š
- åº”ç”¨ä» Electron (`app://.` origin) è¿è¡Œ
- FAL ä¸Šä¼ ç«¯ç‚¹ `https://fal.run/upload` ä¸å…è®¸è·¨åŸŸè¯·æ±‚
- æµè§ˆå™¨ `fetch()` è°ƒç”¨è¢« CORS ç­–ç•¥é˜»æ­¢

### æ ¹æœ¬åŸå›  (Root Cause)
åŸä»£ç ä½¿ç”¨ `falAIClient.uploadImageToFal()` å°†å›¾ç‰‡ä¸Šä¼ åˆ° FAL å­˜å‚¨æœåŠ¡è·å– URLã€‚è¿™ä¼šè§¦å‘ä» Electron æ¸²æŸ“è¿›ç¨‹åˆ° `https://fal.run/upload` çš„ fetch è¯·æ±‚ï¼Œè¢« CORS ç­–ç•¥é˜»æ­¢ã€‚

```typescript
// åŸä»£ç  (é”™è¯¯ - è§¦å‘ CORS)
const imageUrl = await falAIClient.uploadImageToFal(request.characterImage);
```

### è§£å†³æ–¹æ¡ˆ (Solution)
FAL API æ¥å—ä¸¤ç§å›¾ç‰‡æ ¼å¼ï¼š
1. HTTPS URLï¼ˆéœ€è¦ä¸Šä¼ åˆ° FAL å­˜å‚¨ï¼‰
2. **Base64 Data URL**ï¼ˆç›´æ¥åµŒå…¥è¯·æ±‚ä¸­ï¼‰

ä½¿ç”¨ `fileToDataURL()` å°†å›¾ç‰‡è½¬æ¢ä¸º base64 Data URLï¼Œé¿å… CORS é—®é¢˜ï¼š

```typescript
// ä¿®å¤åçš„ä»£ç  (æ­£ç¡® - æ—  CORS é—®é¢˜)
const imageUrl = await fileToDataURL(request.characterImage);
```

### ä»£ç ä¿®æ”¹ (Code Changes)

**æ–‡ä»¶**: `qcut/apps/web/src/lib/ai-video-client.ts`

```typescript
// ä¿®å¤å‰ (ç¬¬ 2891-2894 è¡Œ)
// Upload character image to get a URL (FAL expects URLs, not base64 for this endpoint)
console.log("ğŸ“¤ Uploading reference image to FAL...");
const imageUrl = await falAIClient.uploadImageToFal(request.characterImage);
console.log("âœ… Reference image uploaded:", imageUrl);

// ä¿®å¤å
// Convert reference image to base64 data URL (avoids CORS issues in Electron app)
// FAL API accepts both base64 data URLs and HTTPS URLs
console.log("ğŸ“¤ Converting reference image to base64...");
const imageUrl = await fileToDataURL(request.characterImage);
console.log("âœ… Reference image converted to data URL");
```

åŒæ—¶ç§»é™¤äº†ä¸å†éœ€è¦çš„ `falAIClient` importï¼š
```typescript
// ç§»é™¤
import { falAIClient } from "./fal-ai-client";
```

### æŠ€æœ¯ç»†èŠ‚ (Technical Details)
- FAL API `reference-to-video` ç«¯ç‚¹æ”¯æŒ `image_urls` å‚æ•°æ¥æ”¶ base64 Data URL
- è¿™ä¸å…¶ä»– avatar æ¨¡å‹ (Kling Avatar, ByteDance OmniHuman) ä½¿ç”¨ç›¸åŒçš„æ–¹å¼
- Base64 ç¼–ç ä¼šå¢åŠ è¯·æ±‚å¤§å°çº¦ 33%ï¼Œä½†é¿å…äº† CORS é—®é¢˜
- FAL æ–‡æ¡£è¯´æ˜ï¼šå¯¹äºå¤§æ–‡ä»¶ï¼Œå»ºè®®ä½¿ç”¨ HTTPS URL ä»¥è·å¾—æ›´å¥½æ€§èƒ½ï¼›å¯¹äºå°/ä¸­ç­‰æ–‡ä»¶ï¼Œbase64 å®Œå…¨å¯è¡Œ

### éªŒè¯æ¸…å• (Verification Checklist)
- [x] ç§»é™¤ `falAIClient.uploadImageToFal()` è°ƒç”¨
- [x] ä½¿ç”¨ `fileToDataURL()` è½¬æ¢å›¾ç‰‡
- [x] ç§»é™¤æœªä½¿ç”¨çš„ `falAIClient` import
- [x] Build æˆåŠŸé€šè¿‡
- [x] æ–‡æ¡£æ›´æ–°å®Œæˆ

---

## Implementation Status

### Completed
- [x] FAL API client integration (`ai-video-client.ts`)
- [x] Model configuration in `AI_MODELS` registry (`ai-constants.ts`)
- [x] Avatar tab UI with file uploads (`ai.tsx`)
- [x] Upload constants for image/audio/video (`ai-constants.ts`)
- [x] `generateAvatarVideo` function for API calls
- [x] Support for Kling Avatar Standard and Pro
- [x] Support for WAN Animate/Replace
- [x] Support for ByteDance OmniHuman
- [x] `kling_o1_v2v_reference` model config
- [x] `kling_o1_v2v_edit` model config
- [x] `kling_o1_ref2video` model config
- [x] `kling_o1_i2v` model config
- [x] `generateKlingO1Video()` function
- [x] `generateKlingO1RefVideo()` function
- [x] `MODEL_HELPERS.requiresSourceVideo()` helper
- [x] V2V mode in `AIImageUploadSection`
- [x] Source video state in Image tab
- [x] **BUG FIX (2025-12-03)**: `kling_o1_ref2video` handler in `generateAvatarVideo` function
- [x] **BUG FIX (2025-12-03)**: Validation logic to require image for `kling_o1_ref2video`
- [x] **BUG FIX (2025-12-03)**: Pass `referenceImages` to `useAIGeneration` hook
- [x] **BUG FIX (2025-12-03)**: Use `referenceImages` for `kling_o1_ref2video` API calls
- [x] **BUG FIX (2025-12-03)**: Fix CORS error by using base64 Data URL instead of FAL storage upload

### File References
- UI Component: `qcut/apps/web/src/components/editor/media-panel/views/ai.tsx`
- Image Upload: `qcut/apps/web/src/components/editor/media-panel/views/ai-image-upload.tsx`
- Constants: `qcut/apps/web/src/components/editor/media-panel/views/ai-constants.ts`
- API Client: `qcut/apps/web/src/lib/ai-video-client.ts`
