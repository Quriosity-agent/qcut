# Kling-01

Integration of Kling Video APIs from fal.ai into QCut.

## Overview

This document covers the integration of Kling Video endpoints from fal.ai, as implemented in QCut's AI Video Generation dialog.

### UI Structure

The AI Video Generation dialog (`ai.tsx`) contains four tabs:
- **Text** - Text-to-video generation
- **Image** - Image-to-video generation (includes V2V models)
- **Avatar** - Audio-driven avatar video generation
- **Upscale** - Video upscaling and enhancement

### Implemented Kling Models

From `ai-constants.ts`, the following Kling models are configured:

**Text Tab:**
- `kling_v2_5_turbo` - Kling v2.5 Turbo Pro (text-to-video and image-to-video)
- `kling_v2` - Kling v2.1 Master

**Image Tab:**
- `kling_v2_5_turbo_i2v` - Kling v2.5 Turbo Pro I2V
- `kling_o1_v2v_reference` - Kling O1 Video Reference (V2V)
- `kling_o1_v2v_edit` - Kling O1 Video Edit (V2V)
- `kling_o1_i2v` - Kling O1 Image-to-Video

**Avatar Tab:**
- `kling_avatar_pro` - Kling Avatar Pro
- `kling_avatar_standard` - Kling Avatar Standard
- `kling_o1_ref2video` - Kling O1 Reference-to-Video (uses reference images)

---

## Kling O1 Models

### Video-to-Video Reference
```typescript
// From ai-constants.ts
{
  id: "kling_o1_v2v_reference",
  name: "Kling O1 Video Reference",
  description: "Generate new shots guided by input reference video, preserving motion and camera style",
  price: "0.112",
  resolution: "1080p",
  max_duration: 10,
  category: "image",
  requiredInputs: ["sourceVideo"],
  endpoints: {
    image_to_video: "fal-ai/kling-video/o1/video-to-video/reference",
  },
  default_params: {
    duration: 5,
    aspect_ratio: "auto",
  },
  supportedDurations: [5, 10],
  supportedAspectRatios: ["auto", "16:9", "9:16", "1:1"],
}
```

### Video-to-Video Edit
```typescript
{
  id: "kling_o1_v2v_edit",
  name: "Kling O1 Video Edit",
  description: "Edit videos through natural language instructions while preserving motion structure",
  price: "0.168",
  resolution: "1080p",
  max_duration: 10,
  category: "image",
  requiredInputs: ["sourceVideo"],
  endpoints: {
    image_to_video: "fal-ai/kling-video/o1/video-to-video/edit",
  },
  default_params: {
    duration: 5,
  },
  supportedDurations: [5, 10],
}
```

### Reference-to-Video
```typescript
{
  id: "kling_o1_ref2video",
  name: "Kling O1 Reference-to-Video",
  description: "Transform reference images and elements into consistent video scenes",
  price: "0.112",
  resolution: "1080p",
  max_duration: 10,
  category: "avatar", // Avatar tab - uses reference images
  requiredInputs: ["referenceImages"],
  endpoints: {
    image_to_video: "fal-ai/kling-video/o1/reference-to-video",
  },
  default_params: {
    duration: 5,
    aspect_ratio: "16:9",
    cfg_scale: 0.5,
    negative_prompt: "blur, distort, low quality",
  },
  supportedDurations: [5, 10],
  supportedAspectRatios: ["16:9", "9:16", "1:1"],
}
```

#### FAL API Request Example (reference-to-video)
```json
{
  "prompt": "Take @Image1 as the start frame. Start with a high-angle satellite view of the ancient greenhouse ruin surrounded by nature. The camera swoops down and flies inside the building, revealing the character from @Element1 standing in the sun-drenched center. The camera then seamlessly transitions into a smooth 180-degree orbit around the character, moving to the back view. As the open backpack comes into focus, the camera continues to push forward, zooming deep inside the bag to reveal the glowing stone from @Element2 nestled inside. Cinematic lighting, hopeful atmosphere, 35mm lens. Make sure to keep it as the style of @Image2.",
  "image_urls": [
    "https://v3b.fal.media/files/b/koala/v9COzzH23FGBYdGLgbK3u.png",
    "https://v3b.fal.media/files/b/elephant/5Is2huKQFSE7A7c5uUeUF.png"
  ],
  "elements": [
    {
      "reference_image_urls": [
        "https://v3b.fal.media/files/b/kangaroo/YMpmQkYt9xugpOTQyZW0O.png",
        "https://v3b.fal.media/files/b/zebra/d6ywajNyJ6bnpa_xBue-K.png"
      ],
      "frontal_image_url": "https://v3b.fal.media/files/b/panda/MQp-ghIqshvMZROKh9lW3.png"
    },
    {
      "reference_image_urls": [
        "https://v3b.fal.media/files/b/kangaroo/EBF4nWihspyv4pp6hgj7D.png"
      ],
      "frontal_image_url": "https://v3b.fal.media/files/b/koala/gSnsA7HJlgcaTyR5Ujj2H.png"
    }
  ],
  "duration": "5",
  "aspect_ratio": "16:9"
}
```

**Prompt Syntax:**
- `@Image1`, `@Image2`, etc. - Reference images from `image_urls` array (1-indexed)
- `@Element1`, `@Element2`, etc. - Reference elements from `elements` array (1-indexed)
- Each element can have multiple `reference_image_urls` and one `frontal_image_url`

### Image-to-Video (First/Last Frame)
```typescript
{
  id: "kling_o1_i2v",
  name: "Kling O1 Image-to-Video",
  description: "Animate transitions between start and end frames with cinematic motion",
  price: "0.112",
  resolution: "1080p",
  max_duration: 10,
  category: "image",
  requiredInputs: ["firstFrame"],
  endpoints: {
    image_to_video: "fal-ai/kling-video/o1/image-to-video",
  },
  default_params: {
    duration: 5,
  },
  supportedDurations: [5, 10],
}
```

---

## Kling O1 API Client Functions

### generateKlingO1Video
For video-to-video transformations (Reference and Edit models).

```typescript
export interface KlingO1V2VRequest {
  model: string;
  prompt: string;
  sourceVideo: File;
  duration?: 5 | 10;
  aspect_ratio?: "auto" | "16:9" | "9:16" | "1:1";
  keep_audio?: boolean;
}

export async function generateKlingO1Video(
  request: KlingO1V2VRequest
): Promise<VideoGenerationResponse>
```

**Flow:**
1. Validates FAL API key is configured
2. Validates prompt (max 2500 chars)
3. Converts source video to base64 data URL
4. Builds payload with `video_url`, `prompt`, `duration`, `aspect_ratio`
5. Sends request to FAL API with 3-minute timeout
6. Returns `VideoGenerationResponse` with job_id and video URL

### generateKlingO1RefVideo
For reference-to-video generation.

```typescript
export interface KlingO1Ref2VideoRequest {
  model: string;
  prompt: string;
  image_urls: string[]; // Array of reference image URLs (1-7 images)
  duration?: 5 | 10;
  aspect_ratio?: "16:9" | "9:16" | "1:1";
  cfg_scale?: number;
  negative_prompt?: string;
}

export async function generateKlingO1RefVideo(
  request: KlingO1Ref2VideoRequest
): Promise<VideoGenerationResponse>
```

**Payload:**
```typescript
{
  prompt: trimmedPrompt,
  image_urls: validImageUrls, // Filtered array (1-7 valid URLs)
  duration,
  aspect_ratio,
  cfg_scale,
  negative_prompt,
}
```

---

## UI Components

### Video-to-Video Mode in Image Tab

The `AIImageUploadSection` component (`ai-image-upload.tsx`) now supports three modes:

1. **I2V Mode** - Single image upload for image-to-video models
2. **F2V Mode** - Dual frame upload for frame-to-video models
3. **V2V Mode** - Source video upload for video-to-video models

Mode detection uses `MODEL_HELPERS`:
```typescript
// Check if V2V mode
const requiresSourceVideo = selectedModels.some((id) =>
  MODEL_HELPERS.requiresSourceVideo(id)
);

// Check if F2V mode
const requiresFrameToFrame = selectedModels.some((id) =>
  MODEL_HELPERS.requiresFrameToFrame(id)
);
```

### V2V Upload UI
```typescript
<FileUpload
  id="ai-source-video-input"
  label="Upload Source Video"
  helperText="Required for video-to-video transformation"
  fileType="video"
  acceptedTypes={UPLOAD_CONSTANTS.ALLOWED_VIDEO_TYPES}
  maxSizeBytes={UPLOAD_CONSTANTS.MAX_VIDEO_SIZE_BYTES}
  // ...
/>
```

---

## Text-to-Video Models

### Kling v2.5 Turbo Pro

```typescript
// From ai-constants.ts
{
  id: "kling_v2_5_turbo",
  name: "Kling v2.5 Turbo Pro",
  description: "Latest Kling model with enhanced turbo performance",
  price: "0.18",
  resolution: "1080p",
  max_duration: 10,
  category: "text",
  endpoints: {
    text_to_video: "fal-ai/kling-video/v2.5-turbo/pro/text-to-video",
    image_to_video: "fal-ai/kling-video/v2.5-turbo/pro/image-to-video",
  },
  default_params: {
    duration: 5,
    resolution: "1080p",
    cfg_scale: 0.5,
    aspect_ratio: "16:9",
    enhance_prompt: true,
  },
}
```

### Kling v2.1 Master

```typescript
{
  id: "kling_v2",
  name: "Kling v2.1",
  description: "Premium model with unparalleled motion fluidity",
  price: "0.15",
  resolution: "1080p",
  max_duration: 10,
  endpoints: {
    text_to_video: "fal-ai/kling-video/v2.1/master",
  },
  default_params: {
    duration: 5,
    resolution: "1080p",
  },
}
```

---

## Avatar Models

### Kling Avatar Pro

```typescript
{
  id: "kling_avatar_pro",
  name: "Kling Avatar Pro",
  description: "Premium avatar video generation from image + audio",
  price: "0.25",
  resolution: "1080p",
  max_duration: 10,
  category: "avatar",
  requiredInputs: ["characterImage", "audioFile"],
  endpoints: {
    text_to_video: "fal-ai/kling-video/v1/pro/ai-avatar",
  },
}
```

### Kling Avatar Standard

```typescript
{
  id: "kling_avatar_standard",
  name: "Kling Avatar Standard",
  description: "Standard avatar video generation from image + audio",
  price: "0.15",
  resolution: "720p",
  max_duration: 10,
  category: "avatar",
  requiredInputs: ["characterImage", "audioFile"],
  endpoints: {
    text_to_video: "fal-ai/kling-video/v1/standard/ai-avatar",
  },
}
```

---

## Upload Constants

```typescript
export const UPLOAD_CONSTANTS = {
  // Image uploads
  MAX_IMAGE_SIZE_BYTES: 10 * 1024 * 1024, // 10MB
  MAX_IMAGE_SIZE_LABEL: "10MB",

  // Audio uploads
  ALLOWED_AUDIO_TYPES: ["audio/mpeg", "audio/wav", "audio/aac"],
  MAX_AUDIO_SIZE_BYTES: 50 * 1024 * 1024, // 50MB
  AUDIO_FORMATS_LABEL: "MP3, WAV, AAC",

  // Video uploads
  ALLOWED_VIDEO_TYPES: ["video/mp4", "video/quicktime", "video/x-msvideo"],
  MAX_VIDEO_SIZE_BYTES: 100 * 1024 * 1024, // 100MB
  VIDEO_FORMATS_LABEL: "MP4, MOV, AVI",
} as const;
```

---

## Bug Fix: kling_o1_ref2video Generation Failed (2025-12-03) âœ… RESOLVED

### é—®é¢˜æè¿° (Issue Description)
ç”¨æˆ·åœ¨ Avatar æ ‡ç­¾é¡µé€‰æ‹© `kling_o1_ref2video` æ¨¡å‹åç‚¹å‡»ç”Ÿæˆï¼Œè¿”å› `undefined` å“åº”ï¼Œç”Ÿæˆå¤±è´¥ã€‚

### é”™è¯¯æ—¥å¿—åˆ†æ (Error Log Analysis)
```
step 5: sending generation request for kling_o1_ref2video (avatar tab)
step 5a: post-API response analysis
   - response received: false
   - response is undefined/null
âš ï¸ Response has neither job_id nor video_url: undefined
```

å…³é”®çº¿ç´¢ï¼š
```
hasSelectedImage: false
imageFile: null
```

### æ ¹æœ¬åŸå›  (Root Cause) - ä¸¤ä¸ªé—®é¢˜

**é—®é¢˜ 1: `generateAvatarVideo` å‡½æ•°ç¼ºå°‘å¤„ç†é€»è¾‘**
1. æ¨¡å‹ `kling_o1_ref2video` åœ¨ `ai-constants.ts` ä¸­é…ç½®ä¸º `category: "avatar"`
2. ç”¨æˆ·ä» Avatar æ ‡ç­¾é¡µé€‰æ‹©è¯¥æ¨¡å‹æ—¶ï¼Œè°ƒç”¨ `generateAvatarVideo` å‡½æ•°
3. ä½†è¯¥å‡½æ•°åªå¤„ç†ä»¥ä¸‹æ¨¡å‹ï¼š
   - `wan_animate_replace`
   - `kling_avatar_pro` / `kling_avatar_standard`
   - `bytedance_omnihuman_v1_5`
4. `kling_o1_ref2video` æ²¡æœ‰å¯¹åº”å¤„ç†é€»è¾‘ï¼Œè¿›å…¥ `else` åˆ†æ”¯æŠ›å‡º `Error: Unsupported avatar model`

**é—®é¢˜ 2: éªŒè¯é€»è¾‘è·³è¿‡äº†å›¾ç‰‡æ£€æŸ¥** âš ï¸
```typescript
// åŸä»£ç  (é”™è¯¯)
if (modelId === "kling_o1_ref2video") {
  // Reference images are optional enhancement, no validation needed
  continue;  // è¿™é‡Œè·³è¿‡äº†éªŒè¯ï¼
}
```
éªŒè¯ä»£ç é”™è¯¯åœ°è®¤ä¸º "reference images are optional"ï¼Œå¯¼è‡´æ²¡æœ‰æ£€æŸ¥ `avatarImage`ã€‚

ç”±äº `avatarImage` ä¸º `null`ï¼ŒAPI è°ƒç”¨æ¡ä»¶ `activeTab === "avatar" && avatarImage` ä¸º `false`ï¼Œå¯¼è‡´ `generateAvatarVideo` ä»æœªè¢«è°ƒç”¨ï¼Œ`response` ä¿æŒ `undefined`ã€‚

### ä¿®å¤æ–¹æ¡ˆ (Fixes Applied) âœ…

**ä¿®å¤ 1: æ·»åŠ  API å¤„ç†é€»è¾‘** (`ai-video-client.ts`)
```typescript
} else if (request.model === "kling_o1_ref2video") {
  // Kling O1 Reference-to-Video: transforms reference images into video scenes
  // Uses the image_to_video endpoint with image_urls array and prompt
  endpoint = modelConfig.endpoints.image_to_video || "";

  // Upload character image to get URL (FAL expects URLs for this endpoint)
  console.log("ğŸ“¤ Uploading reference image to FAL...");
  const imageUrl = await falAIClient.uploadImageToFal(request.characterImage);
  console.log("âœ… Reference image uploaded:", imageUrl);

  // Build prompt with @Image1 reference syntax
  let enhancedPrompt = request.prompt || "";
  if (!enhancedPrompt.includes("@Image")) {
    enhancedPrompt = `Use @Image1 as the reference. ${enhancedPrompt}`.trim();
  }

  payload = {
    prompt: enhancedPrompt,
    image_urls: [imageUrl],
    duration: String(request.duration || modelConfig.default_params?.duration || 5),
    aspect_ratio: modelConfig.default_params?.aspect_ratio || "16:9",
    ...(modelConfig.default_params?.cfg_scale && { cfg_scale: modelConfig.default_params.cfg_scale }),
    ...(modelConfig.default_params?.negative_prompt && { negative_prompt: modelConfig.default_params.negative_prompt }),
  };
}
```

**ä¿®å¤ 2: æ·»åŠ éªŒè¯é€»è¾‘** (`use-ai-generation.ts`)
```typescript
// ä¿®å¤åçš„ä»£ç 
// Reference-to-video model requires avatar/reference image
if (modelId === "kling_o1_ref2video" && !avatarImage) {
  validationError =
    "Kling O1 Reference-to-Video requires a reference image";
  break;
}
```

### æ–‡ä»¶ä¿®æ”¹ (Files Modified)
- `qcut/apps/web/src/lib/ai-video-client.ts`
  - æ·»åŠ  `import { falAIClient } from "./fal-ai-client";` (line 7)
  - æ·»åŠ  `kling_o1_ref2video` å¤„ç†åˆ†æ”¯ (lines 2881-2909)
- `qcut/apps/web/src/components/editor/media-panel/views/use-ai-generation.ts`
  - ä¿®å¤éªŒè¯é€»è¾‘ï¼Œè¦æ±‚ `avatarImage` (lines 819-824)

### æŠ€æœ¯ç»†èŠ‚ (Technical Details)
- FAL API `reference-to-video` ç«¯ç‚¹æœŸæœ› `image_urls` ä¸º URL æ•°ç»„ï¼Œä¸æ˜¯ base64
- ä½¿ç”¨ `falAIClient.uploadImageToFal()` ä¸Šä¼ å›¾ç‰‡è·å– URL
- éœ€è¦ä½¿ç”¨ `@Image1` è¯­æ³•åœ¨ prompt ä¸­å¼•ç”¨ä¸Šä¼ çš„å›¾ç‰‡
- è‡ªåŠ¨æ·»åŠ  `cfg_scale` å’Œ `negative_prompt` ä» default_params
- ç”¨æˆ·å¿…é¡»å…ˆä¸Šä¼ å‚è€ƒå›¾ç‰‡æ‰èƒ½ä½¿ç”¨æ­¤æ¨¡å‹

### éªŒè¯æ¸…å• (Verification Checklist)
- [x] Import `falAIClient` added to ai-video-client.ts
- [x] Handler for `kling_o1_ref2video` added in `generateAvatarVideo`
- [x] Model category correctly set to `"avatar"` in ai-constants.ts
- [x] Documentation updated to reflect correct model placement
- [x] **Validation logic fixed** to require `avatarImage` for `kling_o1_ref2video`

### ä¿®å¤éªŒè¯ (Fix Verified) - ç¬¬ä¸€é˜¶æ®µ

éªŒè¯æ—¥å¿—æ˜¾ç¤ºéªŒè¯é€»è¾‘ç”Ÿæ•ˆï¼š
```
âŒ Validation failed!
  - Reason: Kling O1 Reference-to-Video requires a reference image
```

ä½†å‘ç°æ–°é—®é¢˜ï¼šç”¨æˆ·ä¸Šä¼ åˆ° "Reference Images" (Ref 1, Ref 2...) åŒºåŸŸï¼Œä½†ä»£ç æ£€æŸ¥çš„æ˜¯ `avatarImage`ï¼ˆä¸åŒçš„çŠ¶æ€å˜é‡ï¼‰ã€‚

---

## Bug Fix: ç¬¬äºŒé˜¶æ®µ - referenceImages çŠ¶æ€æœªä¼ é€’ (2025-12-03) âœ… RESOLVED

### é—®é¢˜å‘ç°
ç”¨æˆ·æˆªå›¾æ˜¾ç¤ºå·²ä¸Šä¼  Reference Images (Ref 1, Ref 2)ï¼Œä½†éªŒè¯ä»ç„¶å¤±è´¥ã€‚

åŸå› åˆ†æï¼š
- UI æœ‰ä¸¤ä¸ªç‹¬ç«‹çš„å›¾ç‰‡ä¸Šä¼ åŒºåŸŸï¼š
  1. `avatarImage` - å•ä¸ªè§’è‰²å›¾ç‰‡
  2. `referenceImages` - 6ä¸ªå‚è€ƒå›¾ç‰‡æ§½ä½ (Ref 1-6)
- `kling_o1_ref2video` é…ç½®ä¸º `requiredInputs: ["referenceImages"]`
- ä½† `referenceImages` çŠ¶æ€**æ²¡æœ‰ä¼ é€’**åˆ° `useAIGeneration` hook

### ä¿®å¤å†…å®¹

**ä¿®å¤ 1: æ·»åŠ  referenceImages åˆ° props æ¥å£** (`ai-types.ts`)
```typescript
// Avatar-specific props
avatarImage?: File | null;
audioFile?: File | null;
sourceVideo?: File | null;
referenceImages?: (File | null)[];  // æ–°å¢
```

**ä¿®å¤ 2: ä¼ é€’ referenceImages åˆ° hook** (`ai.tsx`)
```typescript
const generation = useAIGeneration({
  // ...
  referenceImages,  // æ–°å¢
  // ...
});
```

**ä¿®å¤ 3: æ¥æ”¶ referenceImages** (`use-ai-generation.ts`)
```typescript
// Avatar-specific props
avatarImage,
audioFile,
sourceVideo,
referenceImages,  // æ–°å¢
```

**ä¿®å¤ 4: æ›´æ–°éªŒè¯é€»è¾‘** (`use-ai-generation.ts`)
```typescript
// Reference-to-video model requires at least one reference image
if (modelId === "kling_o1_ref2video") {
  const hasReferenceImage = referenceImages?.some((img) => img !== null);
  if (!hasReferenceImage) {
    validationError =
      "Kling O1 Reference-to-Video requires at least one reference image";
    break;
  }
}
```

**ä¿®å¤ 5: æ›´æ–° API è°ƒç”¨é€»è¾‘** (`use-ai-generation.ts`)
```typescript
} else if (activeTab === "avatar") {
  // Special handling for kling_o1_ref2video which uses referenceImages
  if (modelId === "kling_o1_ref2video") {
    const firstRefImage = referenceImages?.find((img) => img !== null);
    if (firstRefImage) {
      response = await generateAvatarVideo({
        model: modelId,
        characterImage: firstRefImage,
        prompt: prompt.trim() || undefined,
      });
    }
  } else if (avatarImage) {
    // Other avatar models use avatarImage
    response = await generateAvatarVideo({...});
  }
}
```

### æ–‡ä»¶ä¿®æ”¹ (Files Modified)
- `qcut/apps/web/src/components/editor/media-panel/views/ai-types.ts`
  - æ·»åŠ  `referenceImages` åˆ° `UseAIGenerationProps` æ¥å£
- `qcut/apps/web/src/components/editor/media-panel/views/ai.tsx`
  - ä¼ é€’ `referenceImages` åˆ° `useAIGeneration` hook
- `qcut/apps/web/src/components/editor/media-panel/views/use-ai-generation.ts`
  - æ¥æ”¶ `referenceImages` prop
  - æ›´æ–°éªŒè¯é€»è¾‘æ£€æŸ¥ `referenceImages`
  - æ›´æ–° API è°ƒç”¨ä½¿ç”¨ `referenceImages[0]` ä½œä¸º characterImage
  - æ·»åŠ  `referenceImages` åˆ°ä¾èµ–æ•°ç»„

### ç”¨æˆ·æ“ä½œæŒ‡å— (User Guide)
ä½¿ç”¨ Kling O1 Reference-to-Video æ¨¡å‹çš„æ­¥éª¤ï¼š
1. è¿›å…¥ Avatar æ ‡ç­¾é¡µ
2. **ä¸Šä¼ è‡³å°‘ä¸€å¼ å‚è€ƒå›¾ç‰‡åˆ° "Reference Images" åŒºåŸŸ** (Ref 1, Ref 2, ... Ref 6)
3. è¾“å…¥ promptï¼ˆå¯é€‰ï¼Œå»ºè®®ä½¿ç”¨ `@Image1`, `@Image2` è¯­æ³•å¼•ç”¨å›¾ç‰‡ï¼‰
4. é€‰æ‹© `kling_o1_ref2video` æ¨¡å‹
5. ç‚¹å‡»ç”Ÿæˆ

---

## Bug Fix: ç¬¬ä¸‰é˜¶æ®µ - CORS é”™è¯¯ (2025-12-03) âœ… RESOLVED

### é—®é¢˜æè¿° (Issue Description)
ç”¨æˆ·ä¸Šä¼  Reference Images åç‚¹å‡»ç”Ÿæˆï¼Œå‡ºç° CORS é”™è¯¯ï¼š
```
Access to fetch at 'https://fal.run/upload' from origin 'app://.' has been blocked by CORS policy
```

### é”™è¯¯æ—¥å¿—åˆ†æ (Error Log Analysis)
```
ğŸ“¤ Uploading reference image to FAL...
Access to fetch at 'https://fal.run/upload' from origin 'app://.' has been blocked by CORS policy:
Response to preflight request doesn't pass access control check:
No 'Access-Control-Allow-Origin' header is present on the requested resource.
```

å…³é”®ä¿¡æ¯ï¼š
- åº”ç”¨ä» Electron (`app://.` origin) è¿è¡Œ
- FAL ä¸Šä¼ ç«¯ç‚¹ `https://fal.run/upload` ä¸å…è®¸è·¨åŸŸè¯·æ±‚
- æµè§ˆå™¨ `fetch()` è°ƒç”¨è¢« CORS ç­–ç•¥é˜»æ­¢

### æ ¹æœ¬åŸå›  (Root Cause)
åŸä»£ç ä½¿ç”¨ `falAIClient.uploadImageToFal()` å°†å›¾ç‰‡ä¸Šä¼ åˆ° FAL å­˜å‚¨æœåŠ¡è·å– URLã€‚è¿™ä¼šè§¦å‘ä» Electron æ¸²æŸ“è¿›ç¨‹åˆ° `https://fal.run/upload` çš„ fetch è¯·æ±‚ï¼Œè¢« CORS ç­–ç•¥é˜»æ­¢ã€‚

```typescript
// åŸä»£ç  (é”™è¯¯ - è§¦å‘ CORS)
const imageUrl = await falAIClient.uploadImageToFal(request.characterImage);
```

### è§£å†³æ–¹æ¡ˆ (Solution)
FAL API æ¥å—ä¸¤ç§å›¾ç‰‡æ ¼å¼ï¼š
1. HTTPS URLï¼ˆéœ€è¦ä¸Šä¼ åˆ° FAL å­˜å‚¨ï¼‰
2. **Base64 Data URL**ï¼ˆç›´æ¥åµŒå…¥è¯·æ±‚ä¸­ï¼‰

ä½¿ç”¨ `fileToDataURL()` å°†å›¾ç‰‡è½¬æ¢ä¸º base64 Data URLï¼Œé¿å… CORS é—®é¢˜ï¼š

```typescript
// ä¿®å¤åçš„ä»£ç  (æ­£ç¡® - æ—  CORS é—®é¢˜)
const imageUrl = await fileToDataURL(request.characterImage);
```

### ä»£ç ä¿®æ”¹ (Code Changes)

**æ–‡ä»¶**: `qcut/apps/web/src/lib/ai-video-client.ts`

```typescript
// ä¿®å¤å‰ (ç¬¬ 2891-2894 è¡Œ)
// Upload character image to get a URL (FAL expects URLs, not base64 for this endpoint)
console.log("ğŸ“¤ Uploading reference image to FAL...");
const imageUrl = await falAIClient.uploadImageToFal(request.characterImage);
console.log("âœ… Reference image uploaded:", imageUrl);

// ä¿®å¤å
// Convert reference image to base64 data URL (avoids CORS issues in Electron app)
// FAL API accepts both base64 data URLs and HTTPS URLs
console.log("ğŸ“¤ Converting reference image to base64...");
const imageUrl = await fileToDataURL(request.characterImage);
console.log("âœ… Reference image converted to data URL");
```

åŒæ—¶ç§»é™¤äº†ä¸å†éœ€è¦çš„ `falAIClient` importï¼š
```typescript
// ç§»é™¤
import { falAIClient } from "./fal-ai-client";
```

### æŠ€æœ¯ç»†èŠ‚ (Technical Details)
- FAL API `reference-to-video` ç«¯ç‚¹æ”¯æŒ `image_urls` å‚æ•°æ¥æ”¶ base64 Data URL
- è¿™ä¸å…¶ä»– avatar æ¨¡å‹ (Kling Avatar, ByteDance OmniHuman) ä½¿ç”¨ç›¸åŒçš„æ–¹å¼
- Base64 ç¼–ç ä¼šå¢åŠ è¯·æ±‚å¤§å°çº¦ 33%ï¼Œä½†é¿å…äº† CORS é—®é¢˜
- FAL æ–‡æ¡£è¯´æ˜ï¼šå¯¹äºå¤§æ–‡ä»¶ï¼Œå»ºè®®ä½¿ç”¨ HTTPS URL ä»¥è·å¾—æ›´å¥½æ€§èƒ½ï¼›å¯¹äºå°/ä¸­ç­‰æ–‡ä»¶ï¼Œbase64 å®Œå…¨å¯è¡Œ

### éªŒè¯æ¸…å• (Verification Checklist)
- [x] ç§»é™¤ `falAIClient.uploadImageToFal()` è°ƒç”¨
- [x] ä½¿ç”¨ `fileToDataURL()` è½¬æ¢å›¾ç‰‡
- [x] ç§»é™¤æœªä½¿ç”¨çš„ `falAIClient` import
- [x] Build æˆåŠŸé€šè¿‡
- [x] æ–‡æ¡£æ›´æ–°å®Œæˆ

---

## Bug Fix: ç¬¬å››é˜¶æ®µ - V2Væ¨¡å‹422é”™è¯¯ (2025-12-04) âœ… RESOLVED

### é—®é¢˜æè¿° (Issue Description)
ç”¨æˆ·ä¸Šä¼ è§†é¢‘å¹¶é€‰æ‹© `kling_o1_v2v_edit` æ¨¡å‹ç”Ÿæˆæ—¶ï¼ŒFAL API è¿”å› HTTP 422 é”™è¯¯ï¼š
```
Failed to load resource: the server responded with a status of 422 ()
FAL API error: [object Object]
```

### é”™è¯¯æ—¥å¿—åˆ†æ (Error Log Analysis)
```
ğŸ¬ Starting Kling O1 video-to-video generation
ğŸ“ Model: kling_o1_v2v_edit
ğŸ“ Prompt: change raining into summer...
ğŸ“¤ Converting source video to base64...
âœ… Video converted to data URL
ğŸ¬ Generating video with: fal-ai/kling-video/o1/video-to-video/edit
ğŸ“ Payload: Object
Failed to load resource: the server responded with a status of 422 ()
FAL API error: [object Object]
```

å…³é”®ä¿¡æ¯ï¼š
- HTTP 422 çŠ¶æ€ç  = "Unprocessable Entity"
- è§†é¢‘è¢«è½¬æ¢ä¸º base64 data URL
- FAL API æ‹’ç»äº†è¯·æ±‚

### æ ¹æœ¬åŸå›  (Root Cause)

**FAL API `video-to-video` ç«¯ç‚¹ä¸æ”¯æŒ base64 Data URL ä½œä¸ºè§†é¢‘è¾“å…¥**

æ ¹æ® FAL API æ–‡æ¡£ï¼š
> `video_url` (string): "Reference video URL. Only .mp4/.mov formats supported, 3-10 seconds duration, 720-2160px resolution, max 200MB."

è¯¥ç«¯ç‚¹è¦æ±‚ **HTTPS URL**ï¼Œè€Œé base64 ç¼–ç çš„ Data URLã€‚

å½“å‰ä»£ç å®ç°ï¼š
```typescript
// ai-video-client.ts:2402-2404 (é”™è¯¯)
console.log("ğŸ“¤ Converting source video to base64...");
const videoUrl = await fileToDataURL(request.sourceVideo);
console.log("âœ… Video converted to data URL");
```

### ä¸ºä»€ä¹ˆä¸èƒ½ç®€å•ä½¿ç”¨ `uploadVideoToFal()`

ä¹‹å‰å¯¹äº `kling_o1_ref2video` å›¾ç‰‡ä¸Šä¼ é‡åˆ°äº† CORS é—®é¢˜ï¼Œè§£å†³æ–¹æ¡ˆæ˜¯ä½¿ç”¨ base64 Data URLã€‚
ä½†è§†é¢‘ä¸åŒäºå›¾ç‰‡ï¼š
1. **å›¾ç‰‡ç«¯ç‚¹** (`reference-to-video`): æ”¯æŒ base64 Data URL
2. **è§†é¢‘ç«¯ç‚¹** (`video-to-video`): åªæ”¯æŒ HTTPS URL

ç›´æ¥è°ƒç”¨ `fal.run/upload` ä¼šè§¦å‘ CORS é”™è¯¯ï¼ˆElectron `app://.` originï¼‰ï¼š
```
Access to fetch at 'https://fal.run/upload' from origin 'app://.' has been blocked by CORS policy
```

### è§£å†³æ–¹æ¡ˆ (Solution)

**ä½¿ç”¨ Electron IPC é€šé“ç»•è¿‡ CORS é™åˆ¶**

ç±»ä¼¼äº `fetch-github-stars` çš„æ¨¡å¼ï¼Œåœ¨ Electron ä¸»è¿›ç¨‹ä¸­å¤„ç†è§†é¢‘ä¸Šä¼ ï¼š

1. **æ·»åŠ  IPC Handler** (`electron/main.ts`)
   - ä»æ¸²æŸ“è¿›ç¨‹æ¥æ”¶è§†é¢‘æ•°æ®
   - åœ¨ä¸»è¿›ç¨‹ä¸­è°ƒç”¨ `fal.run/upload`ï¼ˆæ—  CORS é™åˆ¶ï¼‰
   - è¿”å›ä¸Šä¼ åçš„ HTTPS URL

2. **æ·»åŠ  IPC Invoker** (`preload.ts`)
   - æš´éœ² `uploadVideoToFal` æ–¹æ³•ç»™æ¸²æŸ“è¿›ç¨‹

3. **æ›´æ–° API å®¢æˆ·ç«¯** (`ai-video-client.ts`)
   - æ£€æµ‹ Electron ç¯å¢ƒ
   - ä½¿ç”¨ IPC é€šé“ä¸Šä¼ è§†é¢‘
   - å°†è¿”å›çš„ URL ä¼ é€’ç»™ FAL API

### å®ç°è®¡åˆ’ (Implementation Plan)

**æ­¥éª¤ 1: æ·»åŠ  IPC Handler**
```typescript
// electron/main.ts
ipcMain.handle(
  "fal:upload-video",
  async (event, videoData: Uint8Array, filename: string, apiKey: string) => {
    const https = require("https");
    const FormData = require("form-data");

    // æ„å»º multipart form data
    const form = new FormData();
    form.append("file", Buffer.from(videoData), { filename });

    // ä¸Šä¼ åˆ° FAL
    const response = await fetch("https://fal.run/upload", {
      method: "POST",
      headers: {
        Authorization: `Key ${apiKey}`,
      },
      body: form,
    });

    const data = await response.json();
    return data.url;
  }
);
```

**æ­¥éª¤ 2: æ›´æ–° Preload**
```typescript
// electron/preload.ts
contextBridge.exposeInMainWorld("electronAPI", {
  // ...existing methods
  uploadVideoToFal: (videoData: Uint8Array, filename: string, apiKey: string) =>
    ipcRenderer.invoke("fal:upload-video", videoData, filename, apiKey),
});
```

**æ­¥éª¤ 3: æ›´æ–° API å®¢æˆ·ç«¯**
```typescript
// ai-video-client.ts - generateKlingO1Video
// æ£€æµ‹ Electron ç¯å¢ƒå¹¶ä½¿ç”¨ IPC ä¸Šä¼ 
let videoUrl: string;
if (window.electronAPI?.uploadVideoToFal) {
  const videoBuffer = await request.sourceVideo.arrayBuffer();
  videoUrl = await window.electronAPI.uploadVideoToFal(
    new Uint8Array(videoBuffer),
    request.sourceVideo.name,
    falApiKey
  );
} else {
  // æµè§ˆå™¨ç¯å¢ƒ fallbackï¼ˆå¯èƒ½é‡åˆ° CORSï¼‰
  videoUrl = await fileToDataURL(request.sourceVideo);
}
```

### é™„åŠ ä¿®å¤ï¼šé”™è¯¯æ¶ˆæ¯æ ¼å¼åŒ–

å½“å‰é”™è¯¯æ˜¾ç¤º `[object Object]` è€Œéå®é™…é”™è¯¯è¯¦æƒ…ï¼š
```typescript
// ai-video-client.ts:2465
throw new Error(
  `FAL API error: ${errorData.detail || response.statusText}`
);
```

éœ€è¦ä¿®å¤ä¸ºæ­£ç¡®åºåˆ—åŒ–é”™è¯¯å¯¹è±¡ï¼š
```typescript
throw new Error(
  `FAL API error: ${typeof errorData.detail === 'object' ? JSON.stringify(errorData.detail) : (errorData.detail || errorData.message || response.statusText)}`
);
```

### æ–‡ä»¶ä¿®æ”¹æ¸…å• (Files to Modify)
- `qcut/electron/main.ts` - æ·»åŠ  `fal:upload-video` IPC handler
- `qcut/electron/preload.ts` - æš´éœ² `uploadVideoToFal` æ–¹æ³•
- `qcut/apps/web/src/lib/ai-video-client.ts` - ä½¿ç”¨ IPC ä¸Šä¼ è§†é¢‘
- `qcut/apps/web/src/types/electron.d.ts` - æ·»åŠ  TypeScript ç±»å‹å£°æ˜

### æµ‹è¯•æ—¥å¿—åˆ†æ (error5.md - 2025-12-04)

ç”¨æˆ·æµ‹è¯•åå‘ç° IPC é€šé“æœªè¢«æ£€æµ‹åˆ°ï¼š
```
ai-video-client.ts:2425 âš ï¸ Electron IPC not available, falling back to base64 (may fail)
```

**é”™è¯¯æ¶ˆæ¯æ ¼å¼åŒ–å·²ä¿®å¤** - ç°åœ¨æ˜¾ç¤ºå®é™…é”™è¯¯ï¼š
```
FAL API error: [{"loc":["body"],"msg":"Video URL is invalid","type":"input_value_error",...
```

**é—®é¢˜æ ¹å› **: ç”¨æˆ·è¿è¡Œçš„æ˜¯æ—§ç‰ˆæœ¬ Electron åº”ç”¨ï¼ŒæœªåŒ…å«æ–°çš„ IPC handlerã€‚

**è§£å†³æ–¹æ¡ˆ**: éœ€è¦å®Œæ•´é‡å»º Electron åº”ç”¨ï¼š
```bash
cd qcut
bun run build           # é‡å»º web åº”ç”¨
# ç„¶åé‡å»º Electron æ‰“åŒ…
```

### æ·»åŠ çš„è°ƒè¯•æ—¥å¿—

ä¸ºå¸®åŠ©è¯Šæ–­ IPC é—®é¢˜ï¼Œæ·»åŠ äº†è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—ï¼š
```typescript
console.log("ğŸ” [V2V Debug] Checking Electron IPC availability:");
console.log("  - window.electronAPI exists:", !!window.electronAPI);
console.log("  - window.electronAPI?.fal exists:", !!window.electronAPI?.fal);
console.log("  - window.electronAPI?.fal?.uploadVideo exists:", !!window.electronAPI?.fal?.uploadVideo);
console.log("  - window.electronAPI?.isElectron:", window.electronAPI?.isElectron);
```

### éªŒè¯æ¸…å• (Verification Checklist)
- [x] IPC handler å·²æ·»åŠ åˆ° main.ts
- [x] Preload å·²æš´éœ²æ–°æ–¹æ³•
- [x] ai-video-client.ts å·²æ›´æ–°ä½¿ç”¨ IPC
- [x] TypeScript ç±»å‹å·²å£°æ˜
- [x] é”™è¯¯æ¶ˆæ¯æ ¼å¼åŒ–å·²ä¿®å¤ âœ… (error5.md ç¡®è®¤)
- [x] Build æˆåŠŸé€šè¿‡
- [x] æ·»åŠ è¯¦ç»†è°ƒè¯•æ—¥å¿—
- [ ] V2V æ¨¡å‹ç”Ÿæˆæµ‹è¯•é€šè¿‡ (éœ€è¦é‡å»º Electron åº”ç”¨åæµ‹è¯•)

---

## Bug Fix: ç¬¬äº”é˜¶æ®µ - FAL Upload 404é”™è¯¯ (2025-12-04) âœ… RESOLVED

### é—®é¢˜æè¿° (Issue Description)
Electron é‡å»ºå IPC é€šé“æ­£å¸¸å·¥ä½œï¼Œä½† FAL ä¸Šä¼ è¿”å› **404 Not Found**ï¼š
```
ğŸ“¥ [V2V] Upload result: {success: false, hasUrl: false, error: 'Upload failed: 404 - 404: Not Found'}
```

### é”™è¯¯æ—¥å¿—åˆ†æ (Error Log Analysis) - error7.md
```
ğŸ” [V2V Debug] Checking Electron IPC availability:
  - window.electronAPI exists: true
  - window.electronAPI?.fal exists: true           â† âœ… IPC ç°åœ¨å·¥ä½œäº†!
  - window.electronAPI?.fal?.uploadVideo exists: true
  - window.electronAPI?.isElectron: true
âœ… [V2V] Using Electron IPC for video upload (bypasses CORS)
ğŸ“¤ Uploading source video to FAL via Electron IPC...
  - File name: b9243b0e-af6b-4935-acc1-b661c45a62c6.mp4
  - File size: 8883644 bytes
  - ArrayBuffer size: 8883644 bytes
ğŸ“¥ [V2V] Upload result: {success: false, hasUrl: false, error: 'Upload failed: 404 - 404: Not Found'}
```

**å¥½æ¶ˆæ¯**: IPC é€šé“ç°åœ¨æ­£å¸¸å·¥ä½œï¼Electron é‡å»ºæˆåŠŸã€‚
**æ–°é—®é¢˜**: FAL ä¸Šä¼ ç«¯ç‚¹è¿”å› 404ã€‚

### æ ¹æœ¬åŸå›  (Root Cause)

**ä½¿ç”¨äº†é”™è¯¯çš„ FAL ä¸Šä¼ ç«¯ç‚¹ URL**

å½“å‰ä»£ç ä½¿ç”¨:
```typescript
const uploadUrl = "https://fal.run/upload";  // âŒ 404 Not Found
```

æ ¹æ® FAL JavaScript å®¢æˆ·ç«¯æºç  ([fal-js/storage.ts](https://github.com/fal-ai/fal-js))ï¼Œæ­£ç¡®çš„ä¸Šä¼ æµç¨‹æ˜¯**ä¸¤æ­¥èµ°**ï¼š

1. **Step 1: åˆå§‹åŒ–ä¸Šä¼ ** - è·å–ç­¾åä¸Šä¼  URL
   ```
   POST https://rest.alpha.fal.ai/storage/upload/initiate?storage_type=fal-cdn-v3
   ```
   è¿”å›: `{ upload_url: "https://...", file_url: "https://..." }`

2. **Step 2: ä¸Šä¼ æ–‡ä»¶** - ä½¿ç”¨è¿”å›çš„ç­¾å URL
   ```
   PUT {upload_url}
   Content-Type: video/mp4
   Body: <raw video bytes>
   ```

3. **Step 3: ä½¿ç”¨ file_url** - ä¼ é€’ç»™ FAL API

### è§£å†³æ–¹æ¡ˆ (Solution)

æ›´æ–° `electron/main.ts` ä¸­çš„ IPC handler ä½¿ç”¨ä¸¤æ­¥ä¸Šä¼ æµç¨‹:

```typescript
// Step 1: Initiate upload
const initiateUrl = "https://rest.alpha.fal.ai/storage/upload/initiate?storage_type=fal-cdn-v3";
const initResponse = await fetch(initiateUrl, {
  method: "POST",
  headers: {
    "Authorization": `Key ${apiKey}`,
    "Content-Type": "application/json",
  },
  body: JSON.stringify({
    file_name: filename,
    content_type: "video/mp4",
  }),
});
const { upload_url, file_url } = await initResponse.json();

// Step 2: Upload file to signed URL
await fetch(upload_url, {
  method: "PUT",
  headers: { "Content-Type": "video/mp4" },
  body: Buffer.from(videoData),
});

// Return the final URL
return { success: true, url: file_url };
```

### ä»£ç ä¿®æ”¹ (Code Changes)

**æ–‡ä»¶**: `electron/main.ts`
- æ›´æ–° `fal:upload-video` IPC handler ä½¿ç”¨ä¸¤æ­¥ä¸Šä¼ æµç¨‹
- Step 1: POST to `https://rest.alpha.fal.ai/storage/upload/initiate?storage_type=fal-cdn-v3`
- Step 2: PUT file to returned `upload_url`
- Return `file_url` for use in FAL API calls

**æ–‡ä»¶**: `apps/web/src/lib/ai-video-client.ts`
- å¢åŠ è¶…æ—¶æ—¶é—´ä» 3 åˆ†é’Ÿåˆ° 6 åˆ†é’Ÿ (180000ms â†’ 360000ms)
- æ›´æ–°é”™è¯¯æ¶ˆæ¯

### éªŒè¯æ¸…å• (Verification Checklist)
- [x] IPC handler æ›´æ–°ä½¿ç”¨ä¸¤æ­¥ä¸Šä¼ æµç¨‹
- [x] è¶…æ—¶æ—¶é—´å¢åŠ åˆ° 6 åˆ†é’Ÿ
- [x] Electron build æˆåŠŸ
- [x] Web build æˆåŠŸ
- [ ] V2V æ¨¡å‹ç”Ÿæˆæµ‹è¯•é€šè¿‡

### å‚è€ƒèµ„æ–™ (References)
- FAL JS Client Storage: https://github.com/fal-ai/fal-js/blob/main/libs/client/src/storage.ts
- FAL REST API Base: `https://rest.alpha.fal.ai`

---

## Implementation Status

### Completed
- [x] FAL API client integration (`ai-video-client.ts`)
- [x] Model configuration in `AI_MODELS` registry (`ai-constants.ts`)
- [x] Avatar tab UI with file uploads (`ai.tsx`)
- [x] Upload constants for image/audio/video (`ai-constants.ts`)
- [x] `generateAvatarVideo` function for API calls
- [x] Support for Kling Avatar Standard and Pro
- [x] Support for WAN Animate/Replace
- [x] Support for ByteDance OmniHuman
- [x] `kling_o1_v2v_reference` model config
- [x] `kling_o1_v2v_edit` model config
- [x] `kling_o1_ref2video` model config
- [x] `kling_o1_i2v` model config
- [x] `generateKlingO1Video()` function
- [x] `generateKlingO1RefVideo()` function
- [x] `MODEL_HELPERS.requiresSourceVideo()` helper
- [x] V2V mode in `AIImageUploadSection`
- [x] Source video state in Image tab
- [x] **BUG FIX (2025-12-03)**: `kling_o1_ref2video` handler in `generateAvatarVideo` function
- [x] **BUG FIX (2025-12-03)**: Validation logic to require image for `kling_o1_ref2video`
- [x] **BUG FIX (2025-12-03)**: Pass `referenceImages` to `useAIGeneration` hook
- [x] **BUG FIX (2025-12-03)**: Use `referenceImages` for `kling_o1_ref2video` API calls
- [x] **BUG FIX (2025-12-03)**: Fix CORS error by using base64 Data URL instead of FAL storage upload
- [x] **BUG FIX (2025-12-03)**: Fix `canGenerate` validation to check `referenceImages` for `kling_o1_ref2video`
- [x] **BUG FIX (2025-12-03)**: Add V2V model support (`kling_o1_v2v_reference`, `kling_o1_v2v_edit`) in generation logic
- [x] **BUG FIX (2025-12-04)**: Fix V2V 422 error - FAL API requires HTTPS URLs for video input (not base64)
- [x] **BUG FIX (2025-12-04)**: Add Electron IPC handler (`fal:upload-video`) to bypass CORS restrictions
- [x] **BUG FIX (2025-12-04)**: Fix error message formatting (avoid `[object Object]`)
- [x] **DEBUG (2025-12-04)**: Add detailed IPC availability logging for V2V troubleshooting
- [x] **BUG FIX (2025-12-04)**: Fix FAL upload 404 error - use two-step upload process (initiate + PUT)
- [x] **ENHANCEMENT (2025-12-04)**: Increase V2V generation timeout from 3 to 6 minutes

### File References
- UI Component: `qcut/apps/web/src/components/editor/media-panel/views/ai.tsx`
- Image Upload: `qcut/apps/web/src/components/editor/media-panel/views/ai-image-upload.tsx`
- Constants: `qcut/apps/web/src/components/editor/media-panel/views/ai-constants.ts`
- API Client: `qcut/apps/web/src/lib/ai-video-client.ts`
